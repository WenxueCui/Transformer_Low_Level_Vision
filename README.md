# Transformer_Low_Level_Vision
Transformer for low-level vision applications, such as image restoration (denosing, super resolution, deblur)

## 2021

### image 

* [Peking University] Hanting Chen, Yunhe Wang, Tianyu Guo, Chang Xu, Yiping Deng, Zhenhua Liu, Siwei Ma, Chunjing Xu, Chao Xu, Wen Gao: Pre-Trained Image Processing Transformer. [[paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Pre-Trained_Image_Processing_Transformer_CVPR_2021_paper.pdf)[[code]](https://github.com/huawei-noah/Pretrained-IPT)

* [ETH Zurich] Jingyun Liang Jiezhang Cao, Guolei Sun, Kai Zhang, Luc Van Gool, Radu Timofte: SwinIR: Image Restoration Using Swin Transformer. [[paper]](https://arxiv.org/pdf/2108.10257.pdf)[[code]](https://github.com/JingyunLiang/SwinIR)

* [Peking University] Zhisheng Lu, Hong Liu, Juncheng Li, Linlin Zhang: Efficient Transformer for Single Image Super-Resolution. [[paper]](https://arxiv.org/pdf/2108.11084.pdf)

* [USTC] Zhendong Wang, Xiaodong Cun, Jianmin Bao, Jianzhuang Liu: Uformer: A General U-Shaped Transformer for Image Restoration. [[paper]](https://arxiv.org/pdf/2106.03106.pdf)[[code]](https://github.com/ZhendongWang6/Uformer)

* [National University of Defense Technology] Zhengyu Liang, Yingqian Wang, Longguang Wang, Jungang Yang, Shilin Zhou: Light Field Image Super-Resolution with Transformers. [[paper]](https://arxiv.org/pdf/2108.07597.pdf)[[code]](https://github.com/ZhengyuLiang24/LFT)

* [Wuhan Institute of Technology] Yuanzhi Wang, Tao Lu, Yanduo Zhang, Junjun Jiang, Jiaming Wang, Zhongyuan Wang, Jiayi Ma: TANet: A new Paradigm for Global Face Super-resolution via Transformer-CNN Aggregation Network. [[paper]](https://arxiv.org/pdf/2109.08174.pdf)

* [UESTC] Jin-Fan Hu, Ting-Zhu Huang, Liang-Jian Deng: Fusformer: A Transformer-based Fusion Approach for Hyperspectral Image Super-resolution. [[paper]](https://arxiv.org/pdf/2109.02079.pdf)

* [USTB] Chao Yao; Shuaiyong Zhang; Mengyao Yang; Meiqin Liu; Junpeng Qi: Depth Super-Resolution by Texture-Depth Transformer. [[paper]](https://www.researchgate.net/publication/352997384_Depth_Super-Resolution_by_Texture-Depth_Transformer)

* [University of Massachusetts Lowell] Dayang Wang, Zhan Wu, Hengyong Yu:TED-net: Convolution-free T2T Vision Transformer-based Encoder-decoder Dilation network for Low-dose CT Denoising. [[paper]](https://arxiv.org/ftp/arxiv/papers/2106/2106.04650.pdf)

* [Inception Institute of AI] Syed Waqas Zamir, Aditya Arora1 Salman Khan, Munawar Hayat, Fahad Shahbaz Khan, Ming-Hsuan Yang: Restormer: Efficient Transformer for High-Resolution Image Restoration. [[paper]](https://arxiv.org/pdf/2111.09881.pdf)

* [None] Haobo Ji, Xin feng, Wenjie Pei, Jinxing Li, Guangming Lu: U2-Former: A Nested U-shaped Transformer for Image Restoration. [[paper]](https://arxiv.org/pdf/2112.02279.pdf)

* [University of Macau] Zhendong Wang, Xiaodong Cun, Jianmin Bao, Wengang Zhou, Jianzhuang Liu, Houqiang Li: Uformer: A General U-Shaped Transformer for Image Restoration. [[paper]](https://arxiv.org/abs/2106.03106)[[code]](https://github.com/ZhendongWang6/Uformer)

### video

* [ETH Zurich] Jiezhang Cao, Yawei Li, Kai Zhang, Luc Van Gool: Video Super-Resolution Transformer. [[paper]](https://arxiv.org/abs/2106.06847)[[code]](https://github.com/caojiezhang/VSR-Transformer)

* [Nanjing University] Ming Lu, Peiyao Guo, Huiqing Shi, Chuntong Cao and Zhan Ma: Transformer-based Image Compression. [[paper]](https://arxiv.org/pdf/2111.06707.pdf)


## 2022

### Image

* [Tsinghua University] Yuanhao Cai, Jing Lin, Xiaowan Hu, Haoqian Wang,Xin Yuan, Yulun Zhang, Radu Timofte, and Luc Van Gool: Mask-guided Spectral-wise Transformer for Efficient Hyperspectral Image Reconstruction. CVPR 2022. [[paper]](https://arxiv.org/abs/2111.07910)[[code]](https://github.com/caiyuanhao1998/MST/)

* [ETH Zurich] Kai Zhang Yawei Li Jingyun Liang Jiezhang Cao Yulun Zhang Hao Tang Radu Timofte Luc Van Gool: Practical Blind Denoising via Swin-Conv-UNet and Data Synthesis. [[paper]](https://arxiv.org/abs/2203.13278)[[code]](https://github.com/cszn/SCUNet)

* [Tsinghua University] Yuanhao Cai, Jing Lin, Zudi Lin, Haoqian Wang, Yulun Zhang, Hanspeter Pfister, Radu Timofte, Luc Van Gool: MST++: Multi-stage Spectral-wise Transformer for Efficient Spectral Reconstruction. [[paper]](https://arxiv.org/abs/2204.07908)[[code]](https://github.com/caiyuanhao1998/MST-plus-plus)

* [Nanjing University of Posts and Telecommunications] Guangwei Gao, Zixiang Xu, Juncheng Li, Jian Yang, Tieyong Zeng, and Guo-Jun Qi: CTCNet: A CNN-Transformer Cooperation Network for Face Image Super-Resolution. [[paper]](https://arxiv.org/abs/2204.08696)

* [Tampere University] Wenzhu Xing, Karen Egiazarian: Residual Swin Transformer Channel Attention Network for Image Demosaicing. [[paper]](https://arxiv.org/abs/2204.07098)

* [The Chinese University of Hong Kong] Qing Cai1, Yiming Qian, Jinxing Li, Jun Lv, Yee-Hong Yang, Feng Wu, and David Zhang: HIPA: Hierarchical Patch Transformer for Single Image Super Resolution. [[paper]](https://arxiv.org/abs/2203.10247)

* [Johns Hopkins University] Wele Gedara Chaminda Bandara, Vishal M. Patel: HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening. [[paper]](https://arxiv.org/abs/2203.02503)

* [Chengdu Institute of Computer Application Chinese Academy of Sciences] Lishun Wang, Zongliang Wu, Yong Zhong and Xin Yuan: Spectral Compressive Imaging Reconstruction Using Convolution and Spectral Contextual Transformer. [[paper]](https://arxiv.org/abs/2201.05768)

* [National Chung Hsing University] Chi-Mao Fan and Tsung-Jung Liu, Kan-Hsien Liu: SUNet: Swin Transformer UNet for Image Denoising. [[paper]](https://arxiv.org/abs/2202.14009)

* [Technical University of Munich] A. Burakhan Koyuncu, Han Gao, Eckehard Steinbach: contextformer: A Transformer with spatio-channel attention for context modeling in learned image compression. [[paper]](https://arxiv.org/pdf/2203.02452.pdf)

* [Alibaba Group] Yichen Qian, Ming Lin, Xiuyu Sun: EnTroformer: A Transformer-based Entropy Model for Learned Image Compression. [[paper]](https://arxiv.org/pdf/2202.05492.pdf)


### Video

* [Xian Jiaotong University] Chengxu Liu, Huan Yang, Jianlong Fu, Xueming Qian: Learning Trajectory-Aware Transformer for Video Super-Resolution. [[paper]](https://arxiv.org/abs/2204.04216)[[code]](https://github.com/researchmm/TTVSR)

* [ETH Zurich] Jingyun Liang Jiezhang Cao Yuchen Fan Kai Zhang Rakesh Ranjan Yawei Li Radu Timofte Luc Van Gool: VRT: A Video Restoration Transformer. [[paper]](https://arxiv.org/abs/2201.12288)[[code]](https://github.com/JingyunLiang/VRT)

* [Alibaba Group] Meisong Zheng, Qunliang Xing, Minglang Qiao, Mai Xu, Lai Jiang, Huaida Liu and Ying Chen: Progressive Training of A Two-Stage Framework for Video Restoration. [[paper]](https://arxiv.org/abs/2204.09924)

* [Tsinghua University] Mingden Cao, Yanbo Fan, Yong Zhang, Jue Wang, Yujiu Yang: VDTR: Video Deblurring with Transformer. [[paper]](https://arxiv.org/abs/2204.08023)[[code]](https://github.com/ljzycmd/VDTR)

* [University of Hong Kong] Zhaoyang Huang1, Xiaoyu Shi1, Chao Zhang, Qiang Wang, Ka Chun Cheung, Hongwei Qin, Jifeng Dai, and Hongsheng Li: FlowFormer: A Transformer Architecture for Optical Flow. [[paper]](https://arxiv.org/abs/2203.16194)

* [LITIV Laboratory] Xi Ye, Guillaume-Alexandre Bilodeau: VPTR: Efficient Transformers for Video Prediction. [[paper]](https://arxiv.org/abs/2203.15836)[[code]](https://github.com/XiYe20/VPTR)

* [University of Texas] Zhicheng Geng Luming Liang Tianyu Ding Ilya Zharkov: RSTT: Real-time Spatial Temporal Transformer for Space-Time Video Super-Resolution. [[paper]](https://arxiv.org/abs/2203.14186)[[code]](https://github.com/llmpass/RSTT)

* [Tsinghua University] Hai Wang, Xiaoyu Xiang, Yapeng Tian, Wenming Yang, Qingmin Liao: STDAN: Deformable Attention Network for Space-Time Video Super-Resolution. [[paper]](https://arxiv.org/abs/2203.06841)

* [Universitat de Barcelona] Javier Selva, Anders S. Johansen, Sergio Escalera1, Kamal Nasrollahi, Thomas B. Moeslund, Albert Clapes: Video Transformers: A Survey. [[paper]](https://arxiv.org/abs/2201.05991)
